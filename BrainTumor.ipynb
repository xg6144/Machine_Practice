{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_CPP_MIN_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일 경로/파일 개수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_yes_path = './yes/'\n",
    "tumor_no_path = './no/'\n",
    "\n",
    "tumor_yes_file_list = os.listdir(tumor_yes_path)\n",
    "tumor_no_file_list = os.listdir(tumor_no_path)\n",
    "\n",
    "tumor_yes_len = len(tumor_yes_file_list)\n",
    "tumor_no_len = len(tumor_no_file_list)\n",
    "\n",
    "total_len = tumor_yes_len + tumor_no_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "all_img = np.float32(np.zeros((total_len, 224, 224, 3)))\n",
    "all_label = np.float64(np.zeros((total_len, 2)))\n",
    "\n",
    "for img_name in tumor_yes_file_list:\n",
    "    img_path = tumor_yes_path + img_name\n",
    "    img = load_img(img_path, target_size=(224, 224, 3))\n",
    "\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    all_img[num, :, :] = x\n",
    "\n",
    "    all_label[num][1] = 1\n",
    "    num += 1\n",
    "\n",
    "for img_name in tumor_no_file_list:\n",
    "    img_path = tumor_no_path + img_name\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    all_img[num, :, :] = x\n",
    "\n",
    "    all_label[num][0] = 1\n",
    "    num += 1\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    all_img, all_label, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (224, 224, 3)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네트워크 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(input_shape=IMG_SHAPE, weights='imagenet', include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model_lr = 0.0007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               12845184  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 36,433,666\n",
      "Trainable params: 12,845,698\n",
      "Non-trainable params: 23,587,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 8s 620ms/step - loss: 0.6489 - accuracy: 0.7673 - val_loss: 1.9116 - val_accuracy: 0.7843\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 7s 568ms/step - loss: 0.1411 - accuracy: 0.9455 - val_loss: 1.2847 - val_accuracy: 0.8431\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 7s 560ms/step - loss: 0.1231 - accuracy: 0.9455 - val_loss: 1.0401 - val_accuracy: 0.8235\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 7s 559ms/step - loss: 0.0479 - accuracy: 0.9901 - val_loss: 0.8587 - val_accuracy: 0.8627\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 7s 559ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.7789 - val_accuracy: 0.8627\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 7s 559ms/step - loss: 0.0506 - accuracy: 0.9851 - val_loss: 0.7693 - val_accuracy: 0.8627\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 7s 560ms/step - loss: 0.0238 - accuracy: 0.9950 - val_loss: 0.7111 - val_accuracy: 0.8431\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 7s 559ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.6751 - val_accuracy: 0.8431\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 7s 565ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.6673 - val_accuracy: 0.8627\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 7s 566ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.6660 - val_accuracy: 0.8627\n",
      "Success Save Model!\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=model_lr),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(train_input, train_target, epochs=10, batch_size=16, validation_data=(test_input, test_target), shuffle=True)\n",
    "model.save('modelv3.h5')\n",
    "\n",
    "print('Success Save Model!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
